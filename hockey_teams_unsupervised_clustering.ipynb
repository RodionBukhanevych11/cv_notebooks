{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hockey.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T82o9FNClmWU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "75d4ba9c-c19d-4e62-ebfd-550393aaf1d2"
      },
      "source": [
        "!pip install timm filetype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting timm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/42/6a0f5dcb5925532cc40dc5a7f8405bdbee597af36e782ed035b14fcc0946/timm-0.2.1-py3-none-any.whl (225kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 15.2MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 4.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 30kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 40kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 71kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 81kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 92kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 102kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 112kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 122kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 133kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 143kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 153kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 163kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 174kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 184kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 194kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 204kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 215kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 6.9MB/s \n",
            "\u001b[?25hCollecting filetype\n",
            "  Downloading https://files.pythonhosted.org/packages/b4/6b/7bc015da1a576ac037582ae0c5acb675371de9e017e860931e97a428ee31/filetype-1.0.7-py2.py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.6/dist-packages (from timm) (1.6.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from timm) (0.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->timm) (7.0.0)\n",
            "Installing collected packages: timm, filetype\n",
            "Successfully installed filetype-1.0.7 timm-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v62JW6rCTyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import shutil\n",
        "import os\n",
        "import zipfile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import transforms\n",
        "import copy\n",
        "import tqdm\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "import albumentations\n",
        "import torchvision.datasets as dataset\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "import natsort\n",
        "%matplotlib inline\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import datetime\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM0Ulw3hCXEM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "673914a0-84c1-4f80-fd9f-53653be5e52a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Sep  7 07:53:27 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FYHTdV-CYq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip '/content/drive/My Drive/data.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgwv6nLweI9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),                            \n",
        "    transforms.Resize((300,300)),                                  \n",
        "    #transforms.RandomRotation(45),\n",
        "    transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "class ALLDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, root_dir,folder,img_list, transform=None):\n",
        "        self.root_dir=root_dir\n",
        "        self.img_list = img_list\n",
        "        self.transform=transform\n",
        "        \n",
        "        self.folder=folder\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        self.image_name = self.img_list[idx]\n",
        "        image = cv2.imread(os.path.join(self.root_dir,self.folder,self.image_name))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "      \n",
        "        return image,self.image_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64aII0js4M3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y37h-gIcGP1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EicH1RabjYzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6MVkjNklDIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5kZx5Xs1Ijc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model_conv):\n",
        "    model_conv.to(device)\n",
        "    model_conv.eval()\n",
        "    submission=pd.DataFrame()\n",
        "    root_dir='/content/dataset'\n",
        "    folders=os.listdir(root_dir)\n",
        "    i=1\n",
        "    for folder in folders:\n",
        "      print(i)\n",
        "      i=i+1\n",
        "      images=os.listdir(os.path.join(root_dir,folder))\n",
        "      testset = ALLDataset(root_dir, folder, images, transform=data_transforms)\n",
        "      test_load = torch.utils.data.DataLoader(testset,batch_size=10,num_workers = 4)\n",
        "      for batch_i, (data,names) in enumerate(test_load):\n",
        "        with torch.no_grad():\n",
        "            start_time = datetime.datetime.now()\n",
        "            data = data.to(device)\n",
        "            output = model_conv(data)\n",
        "            output=output.cpu().detach().numpy()\n",
        "            print(output.shape)\n",
        "            kmeans = KMeans(n_clusters=2, random_state=1).fit(output)\n",
        "            end_time = datetime.datetime.now()\n",
        "            time_diff = (end_time - start_time)\n",
        "            execution_time = time_diff.total_seconds() * 1000\n",
        "            labels=kmeans.labels_\n",
        "            names=list(names)\n",
        "            teams=dict(zip(names, labels))\n",
        "            sep_teams = defaultdict(list)\n",
        "            for key, val in sorted(teams.items()):\n",
        "              sep_teams[val].append(key)\n",
        "              teams_dict=dict(sep_teams)\n",
        "            teams_dict['team_a'] = teams_dict.pop(0)\n",
        "            teams_dict['team_b'] = teams_dict.pop(1)\n",
        "            folder_row={folder:teams_dict}\n",
        "            team_df=pd.DataFrame.from_dict(folder_row,orient='index')\n",
        "\n",
        "            team_df['time (ms)']=execution_time\n",
        "\n",
        "      submission=submission.append(team_df)\n",
        "  \n",
        "    submission.reset_index(level=0, inplace=True)\n",
        "    submission=submission.rename(columns={\"index\": \"id\"})\n",
        "    submission.team_a=submission.team_a.apply(lambda x: [i.split('.')[0] for i in x])\n",
        "    submission.team_b=submission.team_b.apply(lambda x: [i.split('.')[0] for i in x])\n",
        "    submission.team_a=submission.team_a.apply(lambda x: ','.join(x))\n",
        "    submission.team_b=submission.team_b.apply(lambda x: ','.join(x))\n",
        "\n",
        "    return submission\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y55x0VSyiOLu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "da2150c2-656a-47e4-e14e-403701464047"
      },
      "source": [
        "#model = torchvision.models.mobilenet_v2(pretrained=False, progress=True)\n",
        "from timm.models import efficientnet_b3\n",
        "model = efficientnet_b3(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b3_ra2-cf984f9c.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_ra2-cf984f9c.pth\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CVvR49Olruu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlLIdsq4rX6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "\n",
        "#model.dropout = Identity()\n",
        "#model.fc=Identity()\n",
        "model.classifier=Identity()\n",
        "#model.classifier[1]=Identity()\n",
        "#for m in model.modules():\n",
        "  #if isinstance(m, nn.BatchNorm2d):\n",
        "    #m.eval()\n",
        "#model.AdaptiveAvgPool2d=Identity()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvuem_BilI9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_subm=train_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGb5pZGym-7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sample_subm.to_csv('/content/drive/My Drive/5_subm__efficient_net_bn_off.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2XED1e8nQ1j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d131bde0-55c5-4772-f97d-b7e15f2b3a51"
      },
      "source": [
        "sample_subm.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2200, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIyxQawK6HIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLGgOXIlvfva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}